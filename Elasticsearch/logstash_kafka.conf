## logtash.conf
input {
  tcp {
    host => "10.xxx.xx.xx"
    port => 9250
    mode => "server"
    tags => ["tags"]
    codec => plain{charset=>"UTF-8"}
    }
}
filter {
    ruby{
     code => "event['readunixtime']= event.timestamp.time.getlocal.to_f.to_s"
     add_field =>{
        "app_name"=>"xxx_sdk_apm"
        "app_stage"=>"dev"
        "readtimestamp"=>"%{@timestamp}"
        }
     }
}
# output { stdout { codec => rubydebug } }
output {
    kafka{
# 大数据kafka集群地址
    bootstrap_servers=> "10.132.XX.XX:9092,10.132.XX.XX:9092,10.132.XX.XX:9092,10.132.37.XX:9092"
# 分配给应用的topic
    topic_id=> "xx_xx_apm"
# 异步传输，不保证消息一定传输，速度最快
    acks=>"0"
# 单位是字节,16k
    batch_size=>16384
    codec=>json
  }
}